# entregable4
Entregable para devops

##Punto 1
#ContenerizaciÃ³n, Seguridad y Despliegue con Helm

Este proyecto implementa una aplicaciÃ³n Flask llamada notas, la cual es contenerizada, analizada por herramientas de seguridad (Trivy + Dive) y desplegada en Kubernetes mediante un Helm Chart.
#1. ContenerizaciÃ³n de la aplicaciÃ³n
1.1 ConstrucciÃ³n inicial

Primero se construyÃ³ la imagen:
```
docker build -t app-notas .

```
Pero observamos que dejaba el tag por defecto (latest):
```
REPOSITORY     TAG      SIZE
app-notas      latest   126MB

```
Por lo que se reconstruyÃ³ correctamente con un tag explÃ­cito:
```
docker build -t app-notas:1.0 .

```
Ahora sÃ­:
```
REPOSITORY     TAG      SIZE
app-notas      1.0      126MB

```
AnÃ¡lisis de Vulnerabilidades con Trivy
```
trivy image app-notas:1.0

```
#Resultados del analisis
Resultados del anÃ¡lisis

Sistema operativo (Debian 13.2):

52 vulnerabilidades

-51 LOW
-1 MEDIUM
-0 HIGH
-0 CRITICAL

Dependencias Python:

Total: 8 vulnerabilidades
      1 HIGH
      â†’ afecta a Flask-Cors 4.0.0
      â†’ corregido en 4.0.2

      6 MEDIUM

      1 LOW

âœ” Conclusiones

-No hay vulnerabilidades crÃ­ticas.
-El nivel de riesgo es aceptable para entornos controlados.
-La Ãºnica vulnerabilidad "HIGH" se resuelve actualizando Flask-Cors.
-El resto proviene de librerÃ­as del sistema base Debian y no afectan directamente la app.

#AnÃ¡lisis de la Imagen con Dive

Se instalÃ³ Dive:
```
choco install dive

```
Se analizÃ³ la imagen:
```
dive app-notas:1.0

```


La imagen NO ejecuta procesos como root, ya que usamos:

```
USER appuser
```
Se utilizÃ³ la herramienta **Dive** para inspeccionar la imagen `app-notas:1.0` y evaluar:

- Eficiencia de capas  
- Espacio desperdiciado  
- Buenas prÃ¡cticas de construcciÃ³n


```
| MÃ©trica                                  | Resultado                    |
| ---------------------------------------- | ---------------------------- |
| **TamaÃ±o total de la imagen**            | 126 MB                       |
| **Espacio potencialmente desperdiciado** | 5.6 MB                       |
| **Eficiencia general**                   |   **96%**                    |
| **EjecuciÃ³n del proceso**                | âœ” No corre como root         |
| **Multi-stage build**                    | âœ” Implementado correctamente |

```
#Conclusion:
La imagen estÃ¡ correctamente optimizada.
Dive confirma que el build es eficiente, ya que:

Se usa multi-stage build â†’ se instala todo en una etapa â€œbuilderâ€ y se copia solo lo necesario a la imagen final.

El contenedor no ejecuta procesos como root. Se definiÃ³ un usuario especÃ­fico: USER appuser

Esto mejora la seguridad y sigue buenas prÃ¡cticas recomendadas para contenedores productivos.

El espacio desperdiciado es mÃ­nimo
Un â€œwasted spaceâ€ del 5%.

La estructura de capas es limpia y lÃ³gica, gracias a:
Instalaciones agrupadas en pocas capas (apt-get)
CreaciÃ³n del usuario en una capa separada
Copia limpia de la aplicaciÃ³n

#Despliegue en Kubernetes con Helm

Se creÃ³ un chart Helm:
```
helm create entregable4-chart

```
Luego se modificaron los valores:
```
image:
  repository: app-notas
  tag: "1.0"
  pullPolicy: IfNotPresent

app:
  port: 5000
  env: "dev"

service:
  type: ClusterIP
  port: 5000

```
InstalaciÃ³n:
```
helm install notas ./entregable4-chart

```
Verificacion:
```
kubectl get pods

```

```
```

##Punto 4
# Monitoreo con Prometheus, Grafana y Kubernetes

Este proyecto despliega la aplicaciÃ³n **notas** en Kubernetes utilizando **Helm** y agrega monitoreo con:

- **Prometheus Operator**
- **ServiceMonitor**
- **Grafana**

Incluye ademÃ¡s un dashboard exportado en:  
 `/grafana/dashboard.json`

---

##  Requisitos previos

Asegurar de tener instalado:

- Docker  
- Kubernetes (Docker Desktop o Minikube)  
- kubectl  
- Helm 3  

Verificar el clÃºster:

```bash
kubectl get nodes
```

# 1. Instalar Prometheus Operator

Prometheus es una herramienta de monitoreo y alertas que se usa en enotrnos como kubernetes, microservicios y DevOps.

Desde la app exponemos mÃ©tricas con prometheus_client, y gracias al ServiceMonitor, Prometheus puede descubrir automÃ¡ticamente mi servicio y empezar a recolectarlas.

Agregar repositorio:
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

```
Instalar kube-prometheus-stack:

```bash
helm install monitoring prometheus-community/kube-prometheus-stack

```

Verificar:

```bash
helm install monitoring prometheus-community/kube-prometheus-stack

```

Se aÃ±adiÃ³ un ServiceMonitor:

```
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: notas-servicemonitor
  labels:
    release: prometheus
spec:
  selector:
    matchLabels:
      app: entregable4-chart
  endpoints:
    - port: http
      path: /metrics
      interval: 10s

```
Prometheus detecta las mÃ©tricas expuestas por la app mediante prometheus_client.

#2. Acceder a Grafana

Grafana se incluye automÃ¡ticamente con kube-prometheus-stack.

Exponer el servicio:
```bash
kubectl port-forward -n default svc/monitoring-grafana 3000:80

```

# Desplegar la aplicaciÃ³n notas con Helm
```bash
helm upgrade --install notas-entregable4-chart ./entregable4-chart


```
Verificar el despliegue:
```bash
kubectl get pods


```
# . Verificar que Prometheus scrapea /metrics

Ver los ServiceMonitor disponibles:
```bash
kubectl get servicemonitors


```
Exponer Prometheus:
```bash
kubectl port-forward -n default svc/prometheus-operated 9090:9090


```

Abrir en navegador:

ðŸ”— http://localhost:9090/targets

Debe aparecer algo como:
serviceMonitor/default/notas-servicemonitor
State: UP


Importar dashboard en Grafana

Ruta del archivo exportado:
/grafana/dashboard.json

5. Seguridad Integrada (DevSecOps)
5.1 AnÃ¡lisis estÃ¡tico de cÃ³digo con Semgrep

- Se ejecutÃ³ Semgrep sobre el archivo app.py con las siguientes reglas personalizadas:

- DetecciÃ³n del uso de open() sin validaciÃ³n de ruta.

- Uso de os.getenv() sin sanitizaciÃ³n o validaciÃ³n.

Comando utilizado (para cmd, en powershell no):
```bash
chcp 65001 
```

```bash
semgrep --config=semgrep-rules.yml app.py > reports\semgrep-report.txt
```

Archivo generado:
- reports/semgrep-report.txt

JustificaciÃ³n:
- Las rutas utilizadas con open() son locales (/data/notas.txt) y no se reciben desde el usuario, por lo que se consideran seguras. Las variables de entorno son leÃ­das para configuraciÃ³n (APP_ENV, APP_PORT), y sus valores no alteran el flujo lÃ³gico del sistema.

5.2 Escaneo de dependencias con Snyk

- Se utilizÃ³ Snyk para escanear el archivo requirements.txt.

Comando utilizado:
```bash
snyk test --file=requirements.txt --package-manager=pip --severity-threshold=high --json > reports\snyk-report.txt
```

Archivo generado:
- reports/snyk-report.txt

Observaciones:
- Inicialmente se reportÃ³ un error de paquete faltante (prometheus-client). Luego de instalar las dependencias con pip install -r requirements.txt, el escaneo se ejecutÃ³ exitosamente. No se encontraron vulnerabilidades crÃ­ticas. Se propone mantener versiones especÃ­ficas en requirements.txt para evitar upgrades automÃ¡ticos inseguros.

5.3 PolÃ­ticas de seguridad en Kubernetes con Kyverno

Se implementaron las siguientes polÃ­ticas en la carpeta kyverno-policies/:

- disallow-latest-tag.yaml: ProhÃ­be imÃ¡genes con etiqueta latest.

- cpu-mem-limits.yaml: Obliga a declarar limits de CPU y memoria.

- no-root-user.yaml: Requiere ejecutar como usuario no root.

- require-app-label.yaml: Obliga a definir la etiqueta app.

AplicaciÃ³n de polÃ­ticas:
```bash
kubectl apply -f kyverno-policies/ --recursive
```


ValidaciÃ³n:
Se intentÃ³ crear un pod test-pod-latest.yaml que violaba intencionalmente todas las polÃ­ticas. La solicitud fue rechazada correctamente.

Comando para guardar evidencia:
```bash
kubectl apply -f kyverno-policies/test-pod-latest.yaml > reports\kyverno-validation.log 2>&1
```

Archivo generado:
- reports/kyverno-validation.log

5.4 Monitoreo de seguridad en tiempo de ejecuciÃ³n con Falco

Falco fue instalado mediante Helm:
```bash
helm install falco falcosecurity/falco
```

Evento simulado:
Se ejecutÃ³ un contenedor de Alpine intentando acceder a /etc/shadow, una acciÃ³n considerada sospechosa:
```bash
docker run --rm alpine cat /etc/shadow > NUL
```

Log del evento capturado:
```bash
kubectl logs -l app.kubernetes.io/name=falco > reports/falco-event.log
```

Archivo generado:
- reports/falco-event.log

DescripciÃ³n del evento:
Falco detectÃ³ correctamente el acceso no autorizado a /etc/shadow desde un contenedor. Esta acciÃ³n simulada representa una prÃ¡ctica comÃºn de reconocimiento o acceso no autorizado, y fue bloqueada de acuerdo con las polÃ­ticas de runtime security.
. Comandos Ãºtiles

Ver logs de la app:
```
kubectl logs -l app=entregable4-chart
```

Ver servicios:
```
kubectl get svc
```

Eliminar la app:
```
helm uninstall notas-entregable4-chart
```

Eliminar Prometheus/Grafana:
```
helm uninstall monitoring
```

Estructura del proyecto:
```
entregable4-chart/
 â”œâ”€â”€ templates/
 â”‚   â”œâ”€â”€ deployment.yaml
 â”‚   â”œâ”€â”€ service.yaml
 â”‚   â”œâ”€â”€ servicemonitor.yaml
 â”‚   â””â”€â”€ pvc.yaml
 â”œâ”€â”€ values.yaml
grafana/
 â””â”€â”€ dashboard.json
 ```
#Resultado Final

La app expone mÃ©tricas en /metrics
Prometheus las detecta con ServiceMonitor
Grafana muestra dashboards como:
RPS (requests per second)
Latencia por endpoint
Total de requests






